\chapter{Introduction}
\label{cha:intro}
Nowadays, most real-world information, such as social and biological information, can be well encoded into graphs \citep{lu2011link}. Each vertex represents an entity, an object, or a biological element (proteins, genes, etc.), while each edge represents a relation or an interaction between entities \citep{chang2020benchmark}. Those graphs can be thought of as Knowledge Graphs (KGs), and each connection between two entities is a \textit{fact} \citep{2016}. For example, "Berlin is the capital of Germany" is a fact where \textit{Berlin} is a subject entity ($i$), \textit{Germany} is an object entity ($j$), and their relation/predicate ($k$) is \textit{"is capital of."} By applying KG, different applications have been proved that we can achieve better results like question-answering \citep{bordes2014question, bordes2014open}, semantic parsing \citep{berant2013semantic, heck2013leveraging}, and named entity disambiguation \citep{Damljanovic2012NamedED, 38389}.
% Generally, a fact is represented by a tuple which contains two entities and their relation denoted as $(s,p,o)$, e.g., \textit{(Berlin, isCapitalOf, Germany)}. \textit{Berlin} is subject entity ($s$), \textit{Germany} is object entity ($o$) and their relation/predicate ($p$) is \textit{isCapitalOf}.

Unfortunately, many KGs, such as biological networks \citep{amaral2008truer, stumpf2008estimating, yu2008high}, contain numerous undiscovered relations between two entities. This is essential since existing knowledge graphs often miss many facts, and some of the edges they have are incorrect \citep{angeli2013philosophers}. There are two approaches to adding missing relation: (1) predicting a missing entity based on a given entity and relation - \textit{entity prediction} \citep{wang2017knowledge}, and (2) directly predicting the relation between two entities - \textit{relation prediction} \citep{lin2015modeling, xie2016representation}. However, in most KG studies, adding missing relations between two entities is typically referred to as entity prediction or \textit{entity ranking} \citep{lin2015modeling}. The relation prediction and entity prediction are generally called \textit{link prediction}.
% Formally, the difference between entity prediction and relation prediction would be the model's questions: for entity prediction, the model tries to answer $(s,p,?)$. In contrast, the relation prediction model tries to answer $(s,?,o)$. 

Several models have been proposed to perform the link prediction, but recently, those given more attention are models based on the learning representation of the KG - \textit{knowledge graph embedding (KGE)} \citep{wang2017knowledge}. They have been successfully applied to knowledge graph completion \citep{2016} as well as in downstream tasks and applications such as recommender systems \citep{wang2017knowledge}.
\newline

\noindent\textbf{Problem Statement.} Although most KGE models can perform both entity and relation predictions, \citep{wang2017knowledge} namely RESCAL \citep{nickel2011three}, TransE \citep{bordes2013translating}, ComplEx \citep{trouillon2016complex}, TuckER \citep{balazevic-etal-2019-tucker}, RotatE \citep{sun2019rotate}, and many more, previous KGE studies have only been limited to entity prediction for training, evaluating, and testing the performance of models \citep{yang2014embedding, wang2014knowledge, trouillon2016complex, shang2018endtoend, sun2019rotate}. 
% While relation prediction does not get enough attention \citep{chang2020benchmark}. 
The reason could be that the number of candidates for entity prediction is usually extremely larger than the number of candidates for predicting relation. Despite this, the importance of relation prediction in training and evaluation should not be neglected.

Using a biomedical Knowledge Graph, \citet{chang2020benchmark} pointed out the importance of relation prediction in evaluating KGE models and encouraged analyzing the performance of models on relation prediction. By evaluating relation prediction, relation representations learned by models could directly be evaluated based on model prediction \citep{chang2020benchmark}. For example, two relations "place of birth" and "lived place" could be similar at a certain level, but models must understand that people can live in more than one place throughout their life. If that person is an artist, the "origin place of artist" relation should be similar to the "place of birth" relation as well as the "lived place" relation.

Additionally, \citet{chen2021relation} showed that by combining relation prediction with entity ranking, the models could perform better than using only entity ranking as a training objective. 
% The table \ref{tab:AKBC results} shows that by using the entity ranking with relation prediction, the ComplEx models could outperform the results found by \citet{Ruffinelli2020You} in terms of entity ranking. 
However, \citet{chen2021relation} reported on the evaluation of entity ranking, and models were selected based on the Mean Reciprocal Rank (MRR) of entity ranking. The MRR and Hits@K (Hit ratios of the top-K ranked results) for predicting relations were neglected. 
\newline

\noindent\textbf{Contributions.} Based on those observations, it is essential to conduct a study of relation prediction not only in training objectives but also in evaluation protocol. Thus, it is crucial to (1) conduct a comparative study to analyze the impact of relation prediction on training objectives and on evaluation; (2) evaluate the performance of KGE models on relation prediction in a similar experimental setting. 

As mentioned before, \citet{chen2021relation} have studied the impact of relation prediction on training objectives and reported the results only for entity prediction. Their approach might have been more interesting if the relation prediction performance had also been studied. Therefore, in this thesis, we attempted to reproduce their results and analyze the impact of combining two training objectives on relation prediction performance. 
\newline

\noindent\textbf{Outline of thesis.} The thesis is structured as follows. Chapter 2 provides a common knowledge about Knowledge Graph, Knowledge Graph Embedding, as well as current well-known training objectives, loss function, and evaluation protocols. Additionally, in this chapter, we establish the terminologies as well as the definition we used throughout this thesis. Finally, chapter 2 discusses the relevant papers regarding relation prediction. 

Chapter 3 describes step-by-step how we reproduced the results from \citet{chen2021relation}'s study; we also discuss the differences between two codebases in the chapter as well as to conduct the ablation study to identify the main difference between the two codebases. 

Chapter 4 presents the results of a comparative study. We will discuss the impact of relation prediction not only on training objectives but also on evaluation protocol. Based on the results of the choice models, this chapter also demonstrates the market simulations and measures the willingness to pay in the competitive setting before drawing some managerial implications. 

Based on the results in chapter 4, chapter 5 is where we analyze the results as well as explain the reason why models can achieve those results.

Chapter 6 concludes with a discussion on the main findings and limitations of the study.


% Thus, the goals of the thesis are:
% \begin{enumerate}
%     \item The relation prediction performance of models in a similar settings
%     \item The impact relation prediction on KGE pipeline in:
%     \begin{enumerate}
%         \item Evaluation protocol: 
%         \item Training objective:
%     \end{enumerate}
% \end{enumerate}

% Finally, we identify which training methods or modeling techniques we can add/develop to improve relation prediction (Section).


